{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%HTML\n",
    "<style type=\"text/css\">\n",
    "     \n",
    "\n",
    "    \n",
    "div.h2 {\n",
    "    background-color: #159957;\n",
    "    background-image: linear-gradient(120deg, #155799, #159957);\n",
    "    text-align: left;\n",
    "    color: white;              \n",
    "    padding:9px;\n",
    "    padding-right: 100px; \n",
    "    font-size: 20px; \n",
    "    max-width: 1500px; \n",
    "    margin: auto; \n",
    "    margin-top: 40px; \n",
    "}\n",
    "                                     \n",
    "                                      \n",
    "body {\n",
    "  font-size: 12px;\n",
    "}    \n",
    "     \n",
    "                                    \n",
    "                                      \n",
    "div.h3 {\n",
    "    color: #159957; \n",
    "    font-size: 18px; \n",
    "    margin-top: 20px; \n",
    "    margin-bottom:4px;\n",
    "}\n",
    "   \n",
    "                                      \n",
    "div.h4 {\n",
    "    color: #159957;\n",
    "    font-size: 15px; \n",
    "    margin-top: 20px; \n",
    "    margin-bottom: 8px;\n",
    "}\n",
    "   \n",
    "                                      \n",
    "span.note {\n",
    "    font-size: 5; \n",
    "    color: gray; \n",
    "    font-style: italic;\n",
    "}\n",
    "  \n",
    "                                      \n",
    "hr {\n",
    "    display: block; \n",
    "    color: gray\n",
    "    height: 1px; \n",
    "    border: 0; \n",
    "    border-top: 1px solid;\n",
    "}\n",
    "  \n",
    "                                      \n",
    "hr.light {\n",
    "    display: block; \n",
    "    color: lightgray\n",
    "    height: 1px; \n",
    "    border: 0; \n",
    "    border-top: 1px solid;\n",
    "}   \n",
    "    \n",
    "                                      \n",
    "table.dataframe th \n",
    "{\n",
    "    border: 1px darkgray solid;\n",
    "    color: black;\n",
    "      <table align=\"left\">\n",
    "    ...\n",
    "  </table>\n",
    "    background-color: white;\n",
    "}\n",
    "    \n",
    "                                      \n",
    "table.dataframe td \n",
    "{\n",
    "    border: 1px darkgray solid;\n",
    "    color: black;\n",
    "    background-color: white;\n",
    "    font-size: 11px;\n",
    "    text-align: center;\n",
    "} \n",
    "   \n",
    "            \n",
    "                                      \n",
    "table.rules th \n",
    "{\n",
    "    border: 1px darkgray solid;\n",
    "    color: black;\n",
    "    background-color: white;\n",
    "    font-size: 11px;\n",
    "    align: left;\n",
    "}\n",
    "       \n",
    "                                      \n",
    "table.rules td \n",
    "{\n",
    "    border: 1px darkgray solid;\n",
    "    color: black;\n",
    "    background-color: white;\n",
    "    font-size: 13px;\n",
    "    text-align: center;\n",
    "} \n",
    "   \n",
    "                                      \n",
    "                                      \n",
    "table.rules tr.best\n",
    "{\n",
    "    color: green;\n",
    "}    \n",
    "    \n",
    "                                      \n",
    ".output { \n",
    "    align-items: left; \n",
    "}\n",
    "        \n",
    "                                      \n",
    ".output_png {\n",
    "    display: table-cell;\n",
    "    text-align: left;\n",
    "    margin:auto;\n",
    "}                                          \n",
    "                                                                    \n",
    "                                      \n",
    "                                      \n",
    "</style>  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-2-cfa9972f9d5f>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-2-cfa9972f9d5f>\"\u001b[1;36m, line \u001b[1;32m1\u001b[0m\n\u001b[1;33m    <br>\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "<br>\n",
    "<a id='bkground'></a>\n",
    "<div class=\"h2\"><i>NG-EDA</i></div>\n",
    "<div class=\"h3\">Next-Generation Exploratory Data Analysis:</div>\n",
    "<div class=\"h3\"><i>NFL Run Data</i></div>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing Isolation Forest on Non-Financial Data - 2 KDDCUP99 Sets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to test Isolation Forest (IF), python implementation of which is available in scikit-learn 0.18, on two real datasets from kddcup99. The datasets are the two versions (SA and SF) of the tcpdump portions of the 1998 DARPA off-line Intrusion Detection System dataset, created by MIT Lincoln Lab in 1999.\n",
    "\n",
    "Full dataset description available at http://scikit-learn.org/stable/modules/generated/sklearn.datasets.fetch_kddcup99.html#sklearn.datasets.fetch_kddcup99\n",
    "\n",
    "<b>SA</b> is obtained by simply selecting all the normal data, and a small proportion of abnormal data to give an anomaly ratio of 1%. SA has all 41 attributes.\n",
    "\n",
    "<b>SF</b> is the data where attribute <i>logged_in</i> is positive, thus focusing on the intrusion attack, which gives an anomaly ratio 0.3%. SF has log-transformed 4 attributes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LOF and Isolation Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>LOF</b> is Local Outlier Factor - measures local variation of density of a samplet vs. its neighbors, where locality is determined by k-nearest neighbors. Lower density samples are considered outliers.\n",
    "\n",
    "<b>IF</b> is an ensemble extremely randomized tree-regressor that uses isolation to separate unusual data points.\n",
    "\n",
    "Both, LOF and IF can be used in supervised and unsupervised settings."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip freeze | findstr \"scikit-learn*\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#------------------------------------------------------\n",
    "from sklearn import datasets\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "#------------------------------------------------------\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.neighbors import LocalOutlierFactor\n",
    "from sklearn import svm\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "#------------------------------------------------------\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.metrics import accuracy_score\n",
    "#------------------------------------------------------\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import itertools\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "\n",
    "%matplotlib inline\n",
    "#------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Utility Functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def byte_decoder(val):\n",
    "    # decodes byte literals to strings\n",
    "    return val.decode('utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cm, title, classes=['abnormal', 'normal'],\n",
    "                          cmap=plt.cm.Blues, save=False, saveas=\"MyFigure.png\"):\n",
    "    \n",
    "    # print Confusion matrix with blue gradient colours\n",
    "    \n",
    "    cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "    \n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=90)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.1%'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    \n",
    "    if save:\n",
    "        plt.savefig(saveas, dpi=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_gridsearch_cv(results, estimator, x_min, x_max, y_min, y_max,save=False, saveas=\"MyFigure.png\"):\n",
    "    \n",
    "    # print GridSearch cross-validation for parameters\n",
    "    \n",
    "    plt.figure(figsize=(10,8))\n",
    "    plt.title(\"GridSearchCV for \"+estimator, fontsize=24)\n",
    "\n",
    "    plt.xlabel(estimator)\n",
    "    plt.ylabel(\"Score\")\n",
    "    plt.grid()\n",
    "\n",
    "    ax = plt.axes()\n",
    "    ax.set_xlim(x_min, x_max)\n",
    "    ax.set_ylim(y_min, y_max)\n",
    "\n",
    "    pad = 0.005\n",
    "    X_axis = np.array(results[\"param_\"+estimator].data, dtype=float)\n",
    "\n",
    "    for scorer, color in zip(sorted(scoring), ['b', 'k']):\n",
    "        for sample, style in (('train', '--'), ('test', '-')):\n",
    "            sample_score_mean = results['mean_%s_%s' % (sample, scorer)]\n",
    "            sample_score_std = results['std_%s_%s' % (sample, scorer)]\n",
    "            ax.fill_between(X_axis, sample_score_mean - sample_score_std,\n",
    "                        sample_score_mean + sample_score_std,\n",
    "                        alpha=0.1 if sample == 'test' else 0, color=color)\n",
    "            ax.plot(X_axis, sample_score_mean, style, color=color,\n",
    "                alpha=1 if sample == 'test' else 0.7,\n",
    "                label=\"%s (%s)\" % (scorer, sample))\n",
    "\n",
    "        best_index = np.nonzero(results['rank_test_%s' % scorer] == 1)[0][0]\n",
    "        best_score = results['mean_test_%s' % scorer][best_index]\n",
    "\n",
    "        # Plot a dotted vertical line at the best score for that scorer marked by x\n",
    "        ax.plot([X_axis[best_index], ] * 2, [0, best_score],\n",
    "            linestyle='-.', color=color, marker='x', markeredgewidth=3, ms=8)\n",
    "\n",
    "        # Annotate the best score for that scorer\n",
    "        ax.annotate(\"%0.2f\" % best_score,\n",
    "                (X_axis[best_index], best_score+pad))\n",
    "\n",
    "    plt.legend(loc=\"best\")\n",
    "    plt.grid('off')\n",
    "    plt.tight_layout()\n",
    "    if save:\n",
    "        plt.savefig(saveas, dpi=100)\n",
    "        \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SF has 703,067 records. SA has 976,158 records.\n",
    "SF anomaly ratio is 0.5%.\n",
    "SA anomaly ratio is 0.3%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = 'target'\n",
    "sf = datasets.fetch_kddcup99(subset='SF', percent10=False)\n",
    "dfSF=pd.DataFrame(sf.data, \n",
    "                  columns=[\"duration\", \"service\", \"src_bytes\", \"dst_bytes\"])\n",
    "assert len(dfSF)>0, \"SF dataset no loaded.\"\n",
    "\n",
    "dfSF[target]=sf.target\n",
    "anomaly_rateSF = 1.0 - len(dfSF.loc[dfSF[target]==b'normal.'])/len(dfSF)\n",
    "\n",
    "\"SF Anomaly Rate is:\"+\"{:.1%}\".format(anomaly_rateSF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sa = datasets.fetch_kddcup99(subset='SA', percent10=True)\n",
    "dfSA=pd.DataFrame(sa.data, \n",
    "                  columns=[\"duration\",\"protocol_type\",\"service\",\"flag\",\"src_bytes\",\"dst_bytes\",\"land\",\"wrong_fragment\",\n",
    "                           \"urgent\",\"hot\",\"num_failed_logins\",\"logged_in\",\"num_compromised\",\"root_shell\",\"su_attempted\",\n",
    "                           \"num_root\",\"num_file_creations\",\"num_shells\",\"num_access_files\",\"num_outbound_cmds\",\"is_host_login\",\n",
    "                           \"is_guest_login\",\"count\",\"srv_count\",\"serror_rate\",\"srv_serror_rate\",\"rerror_rate\",\"srv_rerror_rate\",\n",
    "                           \"same_srv_rate\",\"diff_srv_rate\",\"srv_diff_host_rate\",\"dst_host_count\",\"dst_host_srv_count\",\n",
    "                           \"dst_host_same_srv_rate\",\"dst_host_diff_srv_rate\",\"dst_host_same_src_port_rate\",\n",
    "                           \"dst_host_srv_diff_host_rate\",\"dst_host_serror_rate\",\"dst_host_srv_serror_rate\",\n",
    "                           \"dst_host_rerror_rate\",\"dst_host_srv_rerror_rate\"])\n",
    "assert len(dfSA)>0, \"SA dataset not loaded.\"\n",
    "\n",
    "dfSA[target]=sa.target\n",
    "anomaly_rateSA = 1.0 - len(dfSA.loc[dfSA[target]==b'normal.'])/len(dfSA)\n",
    "\n",
    "\"SA Anomaly Rate is:\"+\"{:.1%}\".format(anomaly_rateSA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Data Processing Stage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Non-numeric attributes are label-encoded to integers. \n",
    "All records where target is not <i>normal</i> are converted to single abnormal class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "toDecodeSA = ['protocol_type', 'service', 'flag', target]\n",
    "toDecodeSF = ['service', target]\n",
    "\n",
    "print (\"Original SA Target values:\",set(dfSA[target]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply hot encoding to fields of type string\n",
    "# convert all abnormal target types to single anomaly class\n",
    "\n",
    "dfSF['binary_target'] = [1 if x==b'normal.' else -1 for x in dfSF[target]]\n",
    "dfSA['binary_target'] = [1 if x==b'normal.' else -1 for x in dfSA[target]]\n",
    "\n",
    "leSA = preprocessing.LabelEncoder()\n",
    "\n",
    "for f in toDecodeSA:\n",
    "    dfSA[f] = list(map(byte_decoder, dfSA[f]))\n",
    "    dfSA[f] = leSA.fit_transform(dfSA[f])\n",
    "    \n",
    "leSF = preprocessing.LabelEncoder()\n",
    "\n",
    "for f in toDecodeSF:\n",
    "    dfSF[f] = list(map(byte_decoder, dfSF[f]))\n",
    "    dfSF[f] = leSF.fit_transform(dfSF[f])\n",
    "    \n",
    "dfSA_normed = preprocessing.normalize(dfSA.drop([target,'binary_target'], axis=1))\n",
    "dfSF_normed = preprocessing.normalize(dfSF.drop([target, 'binary_target'], axis=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Train Isolation Forest and Local Outlier Factor in Supervised Setting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SA Dataset result - 41 attributes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split Data Into Train and Test Sets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_sa, X_test_sa, y_train_sa, y_test_sa = train_test_split(dfSA.drop([target, 'binary_target'], axis=1), \n",
    "                                                                dfSA['binary_target'], \n",
    "                                                    test_size=0.33, random_state=11)\n",
    "X_train_nd, X_test_nd, y_train_nd, y_test_nd = train_test_split(dfSA_normed, dfSA['binary_target'], \n",
    "                                                    test_size=0.33, random_state=11)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train Isolation Forest and LOF:\n",
    "<li> num_estimators = 100</li>\n",
    "<li> max_samples = 25%</li>\n",
    "<li> contamination = 15%</li>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clfIF = IsolationForest(max_samples=0.25, random_state=11, contamination=0.15, n_estimators=100, n_jobs=-1)\n",
    "clfLOF = LocalOutlierFactor(n_neighbors=15, metric='euclidean', algorithm='auto', contamination=0.15, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = datetime.datetime.now()\n",
    "clfIF.fit(X_train_sa,y_train_sa)\n",
    "y_pred_train = clfIF.predict(X_train_sa)\n",
    "end = datetime.datetime.now()\n",
    "print (end-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = datetime.datetime.now()\n",
    "y_pred_train_lof = clfLOF.fit_predict(X_train_nd, y_train_nd)\n",
    "end = datetime.datetime.now()\n",
    "print (end-start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results on the SA training set:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "IF achieves 99.5% recall, while getting 12% FP rate. AUC is 94%.\n",
    "\n",
    "<n>LOF achieves 8.3% recall, while getting 15% FP rate. AUC 46%.</n>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_train_sa, y_pred_train, target_names=['anomaly', 'normal']))\n",
    "print (\"AUC: \", \"{:.1%}\".format(roc_auc_score(y_train_sa, y_pred_train)))\n",
    "cm = confusion_matrix(y_train_sa, y_pred_train)\n",
    "plot_confusion_matrix(cm, title=\"IF Confusion Matrix - SA\", save=True, saveas=\"IF_SA.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_train_nd, y_pred_train_lof, target_names=['anomaly', 'normal']))\n",
    "print (\"AUC: \", \"{:.1%}\".format(roc_auc_score(y_train_nd, y_pred_train_lof)))\n",
    "cm = confusion_matrix(y_train_nd, y_pred_train_lof)\n",
    "plot_confusion_matrix(cm, title=\"LOF Confusion Matrix - SA\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## SF Dataset Results - 4 attributes, log-transformed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_sf, X_test_sf, y_train_sf, y_test_sf = train_test_split(dfSF.drop([target, 'binary_target'], axis=1), \n",
    "                                                                dfSF['binary_target'], test_size=0.33, random_state=11)\n",
    "X_train_nd, X_test_nd, y_train_nd, y_test_nd = train_test_split(dfSF_normed, dfSF['binary_target'], \n",
    "                                                    test_size=0.33, random_state=11)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train Isolation Forest and LOF (same parameters):\n",
    "<li> num_estimators = 100</li>\n",
    "<li> max_samples = 25%</li>\n",
    "<li> contamination = 15%</li>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clfIF = IsolationForest(max_samples=0.25, random_state=11, contamination = 0.15, n_estimators=100, n_jobs=-1)\n",
    "clfLOF = LocalOutlierFactor(n_neighbors=15, metric='euclidean', algorithm = 'auto', contamination=0.15, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = datetime.datetime.now()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'datetime' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-c90af9685759>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mstart\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdatetime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdatetime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mclfIF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train_sf\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_train_sf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0my_pred_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclfIF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train_sf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mend\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdatetime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdatetime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mprint\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mend\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mstart\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'datetime' is not defined"
     ]
    }
   ],
   "source": [
    "start = datetime.datetime.now()\n",
    "clfIF.fit(X_train_sf,y_train_sf)\n",
    "y_pred_train = clfIF.predict(X_train_sf)\n",
    "end = datetime.datetime.now()\n",
    "print (end-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "start = datetime.datetime.now()\n",
    "y_pred_train_lof = clfLOF.fit_predict(X_train_nd,y_train_nd)\n",
    "end = datetime.datetime.now()\n",
    "print (end-start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results on SF training set:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "IF achieves the same 100% recall, while getting 14.6% FP rate. AUC is 93%. Similar performance as with SA dataset.\n",
    "\n",
    "<n>LOF achieves 8.2% recall, while getting 15% FP rate. AUC 47%.</n>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_train_sf, y_pred_train, target_names=['anomaly', 'normal']))\n",
    "print (\"AUC: \", \"{:.1%}\".format(roc_auc_score(y_train_sf, y_pred_train)))\n",
    "cm = confusion_matrix(y_train_sf, y_pred_train)\n",
    "plot_confusion_matrix(cm, title=\"IF Confusion Matrix - SF\", save=True, saveas=\"IF_SF.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_train_nd, y_pred_train_lof, target_names=['anomaly', 'normal']))\n",
    "print (\"AUC: \", \"{:.1%}\".format(roc_auc_score(y_train_nd, y_pred_train_lof)))\n",
    "cm = confusion_matrix(y_train_nd, y_pred_train_lof)\n",
    "plot_confusion_matrix(cm, title=\"LOF Confusion Matrix - SF\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "So far Isolation Forest has shown that it:\n",
    "<li> Can outperform LOF on recall and AUC</li>\n",
    "<li> Does not require feature scaling</li>\n",
    "<li> Is faster than LOF (when LOW is called on non-normalised data set)</li>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results on  SA and SF Test Sets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clfIF = IsolationForest(max_samples=0.25, random_state=11, contamination = 0.15, n_estimators=100, n_jobs=-1)\n",
    "\n",
    "clfIF.fit(X_train_sa,y_train_sa)\n",
    "y_pred_test = clfIF.predict(X_test_sa)\n",
    "\n",
    "print(classification_report(y_test_sa, y_pred_test, target_names=['anomaly', 'normal']))\n",
    "print (\"AUC: \", \"{:.1%}\".format(roc_auc_score(y_test_sa, y_pred_test)))\n",
    "cm = confusion_matrix(y_test_sa, y_pred_test)\n",
    "plot_confusion_matrix(cm, title=\"IF Confusion Matrix - SA\", save=True, saveas=\"IF_SA_Test.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clfIF = IsolationForest(max_samples=0.25, random_state=11, contamination = 0.15, n_estimators=100, n_jobs=-1)\n",
    "\n",
    "clfIF.fit(X_train_sf,y_train_sf)\n",
    "y_pred_test = clfIF.predict(X_test_sf)\n",
    "\n",
    "print(classification_report(y_test_sf, y_pred_test, target_names=['anomaly', 'normal']))\n",
    "print (\"AUC: \", \"{:.1%}\".format(roc_auc_score(y_test_sf, y_pred_test)))\n",
    "cm = confusion_matrix(y_test_sf, y_pred_test)\n",
    "plot_confusion_matrix(cm, title=\"IF Confusion Matrix - SF\", save=True, saveas=\"IF_SF_Test.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Setting Parameters of Isolation Forest - n_estimators"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Score is biased towards outlier class (pos_label=-1)!</b>\n",
    "<n><b>n_estimators</b> controls the number of trees that get built.</n>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scoring = {'AUC': 'roc_auc', 'Recall': make_scorer(recall_score, pos_label=-1)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs = GridSearchCV(IsolationForest(max_samples=0.25, random_state=11, contamination = 0.15, n_jobs=-1),\n",
    "                  param_grid={'n_estimators': range(20, 230, 30)},\n",
    "                  scoring=scoring, refit='Recall')\n",
    "gs.fit(X_train_sf, y_train_sf)\n",
    "results = gs.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_gridsearch_cv(results, \"n_estimators\", 0, 230, 0.73, 1.05, save=True, saveas=\"GS_n_est.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# 5. Setting Parameters of Isolation Forest - max_samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>max_samples</b> controls the number of records to draw (with replacement, by default) from the training set to build each tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs_ms = GridSearchCV(IsolationForest(random_state=11, contamination = 0.15, n_estimators=150, n_jobs=-1),\n",
    "                  param_grid={'max_samples': np.arange(0.1, 1.0, 0.1)},\n",
    "                  scoring=scoring, refit='Recall')\n",
    "gs_ms.fit(X_train_sf, y_train_sf)\n",
    "results = gs_ms.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_gridsearch_cv(results, \"max_samples\", 0, 1, 0.73, 1.05, save=True, saveas=\"GS_max_samples.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Setting Parameters of Isolation Forest - contamination"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>contamination</b> controls the threshold of the anomaly score beyond which instances are classified as outliers.\n",
    "<n>SF actual anomaly rate is 0.5%.</n>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs_cont = GridSearchCV(IsolationForest(random_state=11, max_samples=0.10, n_estimators=150, n_jobs=-1),\n",
    "                  param_grid={'contamination': np.arange(0.01, 0.25, 0.05)},\n",
    "                  scoring=scoring, refit='Recall')\n",
    "gs_cont.fit(X_train_sf, y_train_sf)\n",
    "results = gs_cont.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_gridsearch_cv(results, \"contamination\", 0, 0.20, 0.80, 1.08, save=True, saveas=\"GS_cont.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
